{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1b178-f3f6-4f3a-9219-1dd91f72e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c4a0c-f76e-4194-8895-d2e0fa492002",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Label Studio annotations (from the CSV file you provided)\n",
    "csv_file = '/path/to/label-studio-file.csv'\n",
    "annotations = pd.read_csv(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1cf01-50cb-47ce-bbe8-58a585ff5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract mel-spectrograms\n",
    "def extract_mel_spectrogram(audio_path, sr=22050, n_mels=128):\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    mel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_spect_db = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "    return mel_spect_db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c53061-5da4-491d-bf98-f6eda1f357c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare dataset\n",
    "audio_files = []\n",
    "labels = []\n",
    "for _, row in annotations.iterrows():\n",
    "    audio_path = row['audio']  # Path to the audio file\n",
    "    label = row['label']  # Label from Label Studio\n",
    "\n",
    "    # Convert label from JSON string to a numeric label (adjust this as needed)\n",
    "    # Assuming label is something like [{\"labels\": [\"ClassName\"]}]\n",
    "    label_class = eval(row['label'])[0]['labels'][0]\n",
    "\n",
    "    # Load audio and extract mel-spectrogram\n",
    "    mel_spectrogram = extract_mel_spectrogram(audio_path)\n",
    "    \n",
    "    # Resize spectrogram to a fixed shape (e.g., 128x128)\n",
    "    mel_spectrogram = librosa.util.fix_length(mel_spectrogram, size=128)\n",
    "\n",
    "    # Append to the dataset\n",
    "    audio_files.append(mel_spectrogram)\n",
    "    labels.append(label_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556850d9-0e02-4df7-92ef-526768e90d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to numpy arrays and one-hot encode labels\n",
    "X_data = np.array(audio_files)\n",
    "y_labels = to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494e26c-9585-400c-a85f-0cf284f94367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18bdff-9f90-43f4-92b1-cf326f96dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reshape data to fit CNN input (e.g., 128x128x1 for grayscale)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc687e-fa3c-43b7-b7af-b75c99ef8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(labels)), activation='softmax')  # Number of unique classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ee729-e78a-473a-9f57-98847d7824ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d8f26-9a10-46e2-bc03-365609f5fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
